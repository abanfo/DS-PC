{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sparkConf is empty, to take advantges of pre-configures stuff on EMR\n",
    "# 5 nodes, 1 master and 4 slaves\n",
    "# all the configuration is left empty, to take advantge of the pre config in EMR amazon\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# to check the correctness of the program, the dataset testing is imported\n",
    "\n",
    "# importing data from amzon data storage S3 \n",
    "line_1 = sc.textFile('s3://amazonfriends/big_data_1.csv')\n",
    "line_2 = sc.textFile('s3://amazonfriends/big_data_2.csv')\n",
    "line_3 = sc.textFile('s3://amazonfriends/big_data_3.csv')\n",
    "line_4 = sc.textFile('s3://amazonfriends/big_data_4.csv')\n",
    "line_5 = sc.textFile('s3://amazonfriends/big_data_5.csv')\n",
    "\n",
    "# the whole dataset\n",
    "\n",
    "df = sc.union([line_1,line_2,line_3,line_4,line_5])\n",
    "# second option to calculate time\n",
    "start_time = sc.startTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing each line into useful fields in rdd variable\n",
    "# each line have (user,age) values which are assigned as key with a value of 1, one represented the connect friend with the use\n",
    "data = df.map(lambda line: line.split(',')).map(lambda column: ((column[1], float(column[2])), 1))\n",
    "\n",
    "\n",
    "\n",
    "# get age-period for each age\n",
    "# the age range is converted to age group, to be used later\n",
    "def get_age_period(age):\n",
    "    if age in range(16, 20):\n",
    "        return 'teens_youthAdult'\n",
    "    elif age in range(20, 40):\n",
    "        return 'Adult'\n",
    "    elif age in range(40, 60):\n",
    "        return 'MiddleAge'\n",
    "    elif age in range(60, 72):\n",
    "        return 'old'\n",
    "\n",
    "# having rdd with keys (user, age) and values as 1 (friend) will make it easier to iterate over data using \n",
    "# reduceByKey - added the number of friends of a user\n",
    "user_num_friends = data.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "age_group_friends = user_num_friends.map(lambda age: (get_age_period(age[0][1]), age[1]))\n",
    "\n",
    "\n",
    "\n",
    "# after computing number of friends for each user-key (user,age) and mapping it to age-period ->(user,age) is replaced with age group based on age\n",
    "# using aggregation is (more or less the same as reduce by key) will help calculating average number of friends\n",
    "####################################################################################################################\n",
    "# Accumulators are variables that are only “added” to through an associative and commutative operation and can \n",
    "#therefore be efficiently supported in parallel. They can be used to implement counters (as in MapReduce) or sums. \n",
    "#Spark natively supports accumulators of numeric types, and programmers can add support for new types.\n",
    "#-reference (https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html#accumulators)\n",
    "\n",
    "# at this point, to the number of friends, 1 is mapped, it is similar to mapValue to 1\n",
    "##################################################################################################################\n",
    "\n",
    "age_group_friends = age_group_friends.mapValues(lambda x: (x,1))\n",
    "print(age_group_friends.take(30))\n",
    "\n",
    "age_group_total_friends = age_group_friends.reduceByKey(lambda x,y : (x[0]+y[0],x[1]+y[1]))\n",
    "print(age_group_total_friends.take(30))\n",
    "\n",
    "averageByAge = age_group_total_friends.mapValues(lambda x : (x[0]/x[1]))\n",
    "result = averageByAge.collect()\n",
    "for key,value in result:\n",
    "    print(key,value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
